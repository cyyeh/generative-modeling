{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleGAN linear walk - Color in W latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a pretrained model to use here, and set the output directories for trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars\n",
    "output_dir = 'notebooks/models/stylegan_W_color_car'\n",
    "model_url = 'https://drive.google.com/uc?id=1MJ6iCfNtMIRicihwRorsM3b7mmtmK9c3'\n",
    "\n",
    "# # ffhq faces\n",
    "# output_dir = 'notebooks/models/stylegan_W_color_face'\n",
    "# model_url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
    "\n",
    "# # cats\n",
    "# output_dir = 'notebooks/models/stylegan_W_color_cat'\n",
    "# model_url = 'https://drive.google.com/uc?id=1MQywl0FNt6lHu8E_EUqnRbviagS7fbiJ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick learning rate and number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_samples = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Graph and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directory\n",
    "import os\n",
    "os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'output'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import time\n",
    "from resources import tf_lpips_pkg as lpips_tf\n",
    "\n",
    "# this is mostly to solve pickle issues\n",
    "import sys\n",
    "sys.path.append('resources/stylegan')\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "\n",
    "\n",
    "tflib.init_tf()\n",
    "\n",
    "with dnnlib.util.open_url(model_url, cache_dir=config.cache_dir) as f:\n",
    "    _G, _D, Gs = pickle.load(f)\n",
    "    # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
    "    # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
    "    # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsliders = 3 # we use 3 slider dimensions for RGB color\n",
    "\n",
    "dim_z = Gs.input_shape[1]\n",
    "\n",
    "# get original generated output\n",
    "z = tf.placeholder(tf.float32, shape=(None, dim_z))\n",
    "outputs_orig = tf.transpose(Gs.get_output_for(z, None, is_validation=True, \n",
    "                                              randomize_noise=True), [0, 2, 3, 1])\n",
    "\n",
    "img_size = outputs_orig.shape[1]\n",
    "Nchannels = outputs_orig.shape[3]\n",
    "\n",
    "# set target placeholders\n",
    "target = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nchannels))\n",
    "mask = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nchannels))\n",
    "\n",
    "# forward to W latent space\n",
    "out_dlatents = Gs.components.mapping.get_output_for(z, None) #out_dlatents shape: [?, 16, 512]\n",
    "\n",
    "# set slider and learnable walk vector\n",
    "latent_dim = out_dlatents.shape\n",
    "alpha = tf.placeholder(tf.float32, shape=(None, Nsliders))\n",
    "w = tf.Variable(np.random.normal(0.0, 0.1, [1, latent_dim[1], latent_dim[2], Nsliders]), name='walk_intermed', dtype=np.float32)\n",
    "\n",
    "# apply walk\n",
    "out_dlatents_new = out_dlatents\n",
    "for i in range(Nsliders):\n",
    "    out_dlatents_new = out_dlatents_new + tf.reshape(\n",
    "        tf.expand_dims(alpha[:,i], axis=1)* tf.reshape(w[:,:,:,i], (1, -1)), (-1, 16, z.shape[1]))\n",
    "\n",
    "# get output after applying walk\n",
    "transformed_output = tf.transpose(Gs.components.synthesis.get_output_for(\n",
    "    out_dlatents_new, is_validation=True, randomize_noise=True), [0, 2, 3, 1])\n",
    "\n",
    "# L_2 loss\n",
    "loss = tf.losses.compute_weighted_loss(tf.square(transformed_output-target), weights=mask)\n",
    "\n",
    "# Lpips loss\n",
    "loss_lpips = tf.reduce_mean(lpips_tf.lpips(mask*transformed_output, mask*target, \n",
    "                                                  model='net-lin', net='alex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops to rescale the stylegan output range ([-1, 1]) to uint8 range [0, 255]\n",
    "float_im = tf.placeholder(tf.float32, outputs_orig.shape)\n",
    "uint8_im = tflib.convert_images_to_uint8(tf.convert_to_tensor(float_im, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    print([str(i.name) for i in not_initialized_vars])\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        return not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.get_default_session()\n",
    "not_initialized_vars = initialize_uninitialized(sess)\n",
    "\n",
    "# change to loss_lpips to optimize using lpips loss instead\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss, var_list=not_initialized_vars, \n",
    "                                                 name='AdamOpter')\n",
    "\n",
    "# this time init Adam's vars:\n",
    "not_initialized_vars = initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Target Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_np(outputs_zs, alpha):\n",
    "        \n",
    "    if not np.any(alpha): # alpha is all zeros\n",
    "        return outputs_zs, np.ones(outputs_zs.shape)\n",
    "    \n",
    "    assert(outputs_zs.shape[0] == alpha.shape[0])\n",
    "    \n",
    "    target_fn = np.copy(outputs_zs)\n",
    "    for b in range(outputs_zs.shape[0]):\n",
    "        for i in range(3):\n",
    "            target_fn[b,:,:,i] = target_fn[b,:,:,i]+alpha[b,i]\n",
    "\n",
    "    mask_out = np.ones(outputs_zs.shape)\n",
    "    return target_fn, mask_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables(scope='walk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(output_dir, 'train')),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "logger = logging.getLogger()\n",
    "\n",
    "loss_vals = []\n",
    "\n",
    "# train\n",
    "def train(saver):\n",
    "    random_seed = 0\n",
    "    rnd = np.random.RandomState(random_seed)\n",
    "    zs = rnd.randn(num_samples, dim_z)\n",
    "\n",
    "    Loss_sum = 0\n",
    "    Loss_sum_iter = 0\n",
    "    n_epoch = 1\n",
    "    optim_iter = 0\n",
    "    batch_size = 4\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            start_time = time.time()\n",
    "\n",
    "            alpha_val = np.random.random(size=(batch_size, Nsliders))-0.5\n",
    "\n",
    "            s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "            feed_dict_out = {z: zs[s]}\n",
    "            out_zs = sess.run(outputs_orig, feed_dict_out) \n",
    "            target_fn, mask_out = get_target_np(out_zs, alpha_val)\n",
    "            \n",
    "            feed_dict = {z: zs[s], alpha: alpha_val, target: target_fn, mask: mask_out}\n",
    "            curr_loss, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "            Loss_sum = Loss_sum + curr_loss\n",
    "            Loss_sum_iter = Loss_sum_iter + curr_loss\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            logger.info('T, epc, bst, lss, a: {}, {}, {}, {}, {}'.format(elapsed_time, epoch, batch_start, curr_loss, alpha_val))\n",
    "\n",
    "            if (optim_iter % 2500 == 0) and (optim_iter > 0):\n",
    "                saver.save(sess, '{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "            \n",
    "            if (optim_iter % 100 == 0) and (optim_iter > 0):\n",
    "                loss_vals.append(Loss_sum_iter/(100*batch_size))\n",
    "                Loss_sum_iter = 0\n",
    "                print('Loss:', loss_vals)\n",
    "\n",
    "            optim_iter = optim_iter+1\n",
    "            \n",
    "        if optim_iter > 0:\n",
    "            loss_vals.append(Loss_sum_iter/(100*batch_size))\n",
    "            print('average loss with this metric: ', Loss_sum/(optim_iter*batch_size))\n",
    "    saver.save(sess, '{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(saver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image import imgrid, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show learned samples\n",
    "\n",
    "num_samples_vis = 6\n",
    "batch_size = 1\n",
    "a = np.linspace(0, 1, 6)\n",
    "\n",
    "random_seed = 0\n",
    "rnd = np.random.RandomState(random_seed)\n",
    "zs = rnd.randn(num_samples_vis, dim_z)\n",
    "\n",
    "for batch_num, batch_start in enumerate(range(0, num_samples_vis, batch_size)):\n",
    "    \n",
    "    ims = []\n",
    "    targets = []\n",
    "    \n",
    "    s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "    input_test = {z:zs[s]}\n",
    "\n",
    "    out_input_test = sess.run(outputs_orig, input_test)\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "        alpha_val = np.ones((zs[s].shape[0], Nsliders)) * -a[i]\n",
    "        alpha_val[:, 1] = a[i]\n",
    "        target_fn,_ = get_target_np(out_input_test, alpha_val) #, show_img=True, show_mask=True)\n",
    "        im_out = sess.run(transformed_output, {z: zs[s], alpha: alpha_val})\n",
    "        \n",
    "        # rescale\n",
    "        im_out = sess.run(uint8_im, {float_im: im_out})\n",
    "        target_fn = sess.run(uint8_im, {float_im: target_fn})\n",
    "        \n",
    "        ims.append(im_out)\n",
    "        targets.append(target_fn)\n",
    "    im_stack = np.concatenate(targets + ims).astype(np.uint8)\n",
    "    imshow(imgrid(im_stack, cols = len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel('num samples, lr{}'.format(lr))\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
