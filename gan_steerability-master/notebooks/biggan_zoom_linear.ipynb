{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigGAN linear walk - Zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'notebooks/models/biggan_linear_zoom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick learning rate and number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_samples = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Graph and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directory\n",
    "import os\n",
    "os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'output'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = 'https://tfhub.dev/deepmind/biggan-256/2'\n",
    "\n",
    "import io\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import time\n",
    "from resources import tf_lpips_pkg as lpips_tf\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "print('Loading BigGAN module from:', module_path)\n",
    "module = hub.Module(module_path)\n",
    "\n",
    "inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n",
    "          for k, v in module.get_input_info_dict().items()}\n",
    "output = module(inputs)\n",
    "\n",
    "print('Inputs:\\n', '\\n'.join(\n",
    "    '  {}: {}'.format(*kv) for kv in inputs.items()))\n",
    "print('Output:', output)\n",
    "\n",
    "input_z = inputs['z']\n",
    "input_y = inputs['y']\n",
    "input_trunc = inputs['truncation']\n",
    "dim_z = input_z.shape.as_list()[1]\n",
    "vocab_size = input_y.shape.as_list()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input placeholders\n",
    "Nsliders = 1\n",
    "z = tf.placeholder(tf.float32, shape=(None, dim_z))\n",
    "y = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "truncation = tf.placeholder(tf.float32, shape=None)\n",
    "\n",
    "# original output\n",
    "inputs_orig = {u'y': y,\n",
    "               u'z': z,\n",
    "               u'truncation': truncation}\n",
    "outputs_orig = module(inputs_orig)\n",
    "\n",
    "img_size = outputs_orig.shape[1].value\n",
    "num_channels = outputs_orig.shape[-1].value\n",
    "\n",
    "# output placeholders\n",
    "target = tf.placeholder(tf.float32, shape=(\n",
    "    None, img_size, img_size, num_channels))\n",
    "mask = tf.placeholder(tf.float32, shape=(\n",
    "    None, img_size, img_size, num_channels))\n",
    "\n",
    "# set walk parameters\n",
    "alpha = tf.placeholder(tf.float32, shape=(None, Nsliders))\n",
    "w = tf.Variable(np.random.normal(0.0, 0.1, [1, z.shape[1], Nsliders]),\n",
    "        name='walk', dtype=np.float32)\n",
    "\n",
    "# transform the output\n",
    "z_new = z\n",
    "for i in range(Nsliders):\n",
    "    z_new = z_new+tf.expand_dims(alpha[:,i], axis=1)*w[:,:,i]\n",
    "transformed_inputs = {u'y': y,\n",
    "                      u'z': z_new,\n",
    "                      u'truncation': truncation}\n",
    "transformed_output = module(transformed_inputs)\n",
    "\n",
    "# losses\n",
    "loss = tf.losses.compute_weighted_loss(tf.square(\n",
    "    transformed_output-target), weights=mask)\n",
    "loss_lpips = tf.reduce_mean(lpips_tf.lpips(\n",
    "    mask*transformed_output, mask*target, model='net-lin', net='alex'))\n",
    "\n",
    "# train op \n",
    "# change to loss to loss_lpips to optimize lpips loss\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(\n",
    "    loss, var_list=tf.trainable_variables(scope=None), name='AdamOpter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(initializer)\n",
    "saver = tf.train.Saver(tf.trainable_variables(scope=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Target Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_np(outputs_zs, alpha):\n",
    "    \n",
    "    mask_fn = np.ones(outputs_zs.shape)\n",
    "    \n",
    "    if alpha == 1:\n",
    "        return outputs_zs, mask_fn\n",
    "    \n",
    "    new_size = int(alpha*img_size)\n",
    "\n",
    "    ## crop\n",
    "    if alpha < 1:\n",
    "        output_cropped = outputs_zs[:,img_size//2-new_size//2:img_size//2+new_size//2, img_size//2-new_size//2:img_size//2+new_size//2,:]\n",
    "        mask_cropped = mask_fn\n",
    "    \n",
    "    ## padding\n",
    "    else:\n",
    "        output_cropped = np.zeros((outputs_zs.shape[0], new_size, new_size, outputs_zs.shape[3]))\n",
    "        mask_cropped = np.zeros((outputs_zs.shape[0], new_size, new_size, outputs_zs.shape[3]))\n",
    "        output_cropped[:, new_size//2-img_size//2:new_size//2+img_size//2, new_size//2-img_size//2:new_size//2+img_size//2,:] = outputs_zs \n",
    "        mask_cropped[:, new_size//2-img_size//2:new_size//2+img_size//2, new_size//2-img_size//2:new_size//2+img_size//2,:] = mask_fn\n",
    "    \n",
    "    ## Resize\n",
    "    target_fn = np.zeros(outputs_zs.shape)\n",
    "    mask_out = np.zeros(outputs_zs.shape)\n",
    "    for i in range(outputs_zs.shape[0]):\n",
    "        target_fn[i,:,:,:] = cv2.resize(output_cropped[i,:,:,:], (img_size, img_size), interpolation = cv2.INTER_LINEAR)\n",
    "        mask_out[i,:,:,:] = cv2.resize(mask_cropped[i,:,:,:], (img_size, img_size), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "    mask_out[np.nonzero(mask_out)] = 1.\n",
    "    assert(np.setdiff1d(mask_out, [0., 1.]).size == 0)\n",
    "\n",
    "    return target_fn, mask_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sampling operations\n",
    "from graphs.biggan.graph_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This can be train.py\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(output_dir, 'train')),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "logger = logging.getLogger()\n",
    "\n",
    "loss_vals = []\n",
    "\n",
    "\n",
    "# train\n",
    "def train(saver):\n",
    "    trunc=1.0\n",
    "    noise_seed=0\n",
    "    zs = truncated_z_sample(num_samples, trunc, noise_seed)\n",
    "    ys = np.random.randint(0,vocab_size,size=zs.shape[0])\n",
    "    ys = one_hot_if_needed(ys, vocab_size)\n",
    "\n",
    "    Loss_sum = 0\n",
    "    n_epoch = 1\n",
    "    Loss_sum_iter = 0\n",
    "    optim_iter = 0\n",
    "    batch_size = 4\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            start_time = time.time()\n",
    "\n",
    "            coin = np.random.uniform(0, 1)\n",
    "            if coin <= 0.5:\n",
    "                alpha_val = np.random.uniform(0.25, 1.) \n",
    "            else:\n",
    "                alpha_val = np.random.uniform(1., 4.) \n",
    "\n",
    "            s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "            feed_dict_out = {z: zs[s], y: ys[s], truncation: trunc}\n",
    "            out_zs = sess.run(outputs_orig, feed_dict_out)\n",
    "\n",
    "            target_fn, mask_out = get_target_np(out_zs, alpha_val)\n",
    "            \n",
    "\n",
    "            alpha_val_for_graph = np.ones((zs[s].shape[0], Nsliders)) * np.log(alpha_val)\n",
    "            feed_dict = {z: zs[s], y: ys[s], truncation: trunc, alpha: alpha_val_for_graph, target: target_fn, mask: mask_out}\n",
    "            \n",
    "            curr_loss, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "            Loss_sum = Loss_sum + curr_loss\n",
    "            Loss_sum_iter = Loss_sum_iter + curr_loss\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            logger.info('T, epc, bst, lss, a: {}, {}, {}, {}, {}'.format(elapsed_time, epoch, batch_start, curr_loss, alpha_val))\n",
    "\n",
    "\n",
    "            if (optim_iter % 100 == 0) and (optim_iter > 0):\n",
    "                saver.save(sess, './{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "\n",
    "            if (optim_iter % 100 == 0) and (optim_iter > 0):\n",
    "                loss_vals.append(Loss_sum_iter/(100*batch_size))\n",
    "                Loss_sum_iter = 0\n",
    "                # print('Loss:', loss_vals)\n",
    "                \n",
    "            optim_iter = optim_iter+1\n",
    "            \n",
    "    if optim_iter > 0:\n",
    "        print('average loss with this metric: ', Loss_sum/(optim_iter*batch_size))\n",
    "    saver.save(sess, \"./{}/{}/model_{}.ckpt\".format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WAIT ######################\n",
    "best_w = w.eval(sess)\n",
    "# print('best_w before restore:', best_w)\n",
    "print(best_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(saver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image import imgrid, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To restore previous w:\n",
    "saver.restore(sess, \"./{}/{}/model_{}.ckpt\".format(output_dir, 'output', 10000))\n",
    "best_w = w.eval(sess)\n",
    "# print('best_w at restore:', best_w)\n",
    "print(best_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: show imgs \n",
    "# this can be test.py\n",
    "\n",
    "category = 207\n",
    "\n",
    "a = np.array([8, 4, 2, 1, 0.5, 0.25, 0.125])\n",
    "\n",
    "trunc = 0.5\n",
    "noise_seed= 0  \n",
    "num_samples_vis = 6\n",
    "batch_size = 1\n",
    "\n",
    "zs = truncated_z_sample(num_samples_vis, trunc, noise_seed)\n",
    "ys = np.array([category] * zs.shape[0])\n",
    "ys = one_hot_if_needed(ys, vocab_size)\n",
    "\n",
    "for batch_num, batch_start in enumerate(range(0, num_samples_vis, batch_size)):\n",
    "\n",
    "    ims = []\n",
    "    targets = []\n",
    "\n",
    "    s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "    input_test = {y: ys[s],\n",
    "                  z: zs[s],\n",
    "                  truncation: trunc}\n",
    "\n",
    "    out_input_test = sess.run(outputs_orig, input_test)\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "        target_fn, mask_out = get_target_np(out_input_test, a[i])\n",
    "        \n",
    "        alpha_val_for_graph = np.ones((zs[s].shape[0], Nsliders)) * np.log(a[i])\n",
    "        \n",
    "        best_inputs = {z: zs[s], y: ys[s], truncation: trunc, alpha: alpha_val_for_graph, target: target_fn, mask: mask_out}\n",
    "        best_im_out = sess.run(transformed_output, best_inputs)\n",
    "       \n",
    "        # collect images\n",
    "        ims.append(np.uint8(np.clip(((best_im_out + 1) / 2.0) * 256, 0, 255)))\n",
    "        targets.append(np.uint8(np.clip(((target_fn + 1) / 2.0) * 256, 0, 255)))\n",
    "        \n",
    "    im_stack = np.concatenate(targets + ims).astype(np.uint8)\n",
    "    imshow(imgrid(im_stack, cols = len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel('num samples, lr{}'.format(lr))\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
